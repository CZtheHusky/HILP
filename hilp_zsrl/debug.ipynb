{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06567ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False  True  True False  True  True  True  True]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "batch_size = 10\n",
    "p_randomgoal = 0.5\n",
    "mask = np.random.rand(batch_size) <= p_randomgoal\n",
    "print(mask)\n",
    "print(mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1bfa12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1105914/1848340779.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dataset = torch.load(\"/root/workspace/exorl/datasets/walker/rnd/replay.pt\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dataset = torch.load(\"/root/workspace/exorl/datasets/walker/rnd/replay.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d431d548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset._episodes_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d489cca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['observation', 'action', 'reward', 'discount', 'physics'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset._storage.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fd66875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1001, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset._storage['reward'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac98c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = dataset._storage['observation'].reshape(-1, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4532104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88ad6638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1001, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset._storage['action'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2288b7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1001, 18)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset._storage['physics'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7010da35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4\n",
      " 4 4 4 4 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "episode_ends = np.array([5, 11, 16, 33, 44])\n",
    "episode_id = np.repeat(np.arange(len(episode_ends)), np.diff([0, *episode_ends]))\n",
    "print(episode_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af15ccc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 11, 28, 39, 50])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep_len = [5, 6, 17, 11, 11]\n",
    "episode_ends = np.cumsum(ep_len)\n",
    "episode_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "663dc96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing result: exp_local/offline/20250915060743/eval_result/70000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/80000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/90000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/100000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/110000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/120000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/130000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/140000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/150000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/160000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/170000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/180000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/190000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/200000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/210000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/220000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/230000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/240000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/250000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/260000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/270000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/280000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/290000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/300000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/310000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/320000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/330000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/340000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/350000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/360000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/370000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/380000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/390000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/400000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/410000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/420000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/430000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/440000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/450000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/460000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/470000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/480000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/490000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/500000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/510000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/520000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/530000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/540000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/550000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/560000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/570000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/580000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/590000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/600000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/610000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/620000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/630000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/640000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/650000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/660000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/670000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/680000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/690000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/700000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/710000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/720000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/730000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/740000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/750000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/760000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/770000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/780000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/790000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/800000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/810000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/820000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/830000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/840000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/850000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/860000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/870000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/880000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/890000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/900000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/910000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/920000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/930000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/940000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/950000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/960000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/970000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/980000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/990000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1000000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1010000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1020000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1030000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1040000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1050000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1060000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1070000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1080000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1090000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1100000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1110000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1120000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1130000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1140000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1150000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1160000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1170000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1180000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1190000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1200000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1210000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1220000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1230000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1240000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1250000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1260000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1270000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1280000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1290000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1300000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1310000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1320000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1330000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1340000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1350000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1360000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1370000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1380000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1390000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1400000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1410000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1420000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1430000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1440000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1450000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1460000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1470000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1480000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1490000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1500000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1510000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1520000\n",
      "Removing result: exp_local/offline/20250915060743/eval_result/1530000\n",
      "Removing model: exp_local/offline/20250915061048/models/1270000.pt\n",
      "Removing model: exp_local/offline/20250915061048/models/1280000.pt\n",
      "Removing model: exp_local/offline/20250915061048/models/1290000.pt\n",
      "Removing model: exp_local/offline/20250915061048/models/1300000.pt\n",
      "Removing model: exp_local/offline/20250915061048/models/1310000.pt\n",
      "Removing model: exp_local/offline/20250915061048/models/1320000.pt\n",
      "Removing model: exp_local/offline/20250915061048/models/1330000.pt\n",
      "Removing model: exp_local/offline/20250915061048/models/1340000.pt\n",
      "Removing model: exp_local/offline/20250915061048/models/1350000.pt\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/0\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/10000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/20000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/30000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/40000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/50000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/60000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/70000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/80000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/90000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/100000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/110000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/120000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/130000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/140000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/150000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/160000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/170000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/180000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/190000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/200000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/210000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/220000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/230000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/240000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/250000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/260000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/270000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/280000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/290000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/300000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/310000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/320000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/330000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/340000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/350000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/360000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/370000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/380000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/390000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/400000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/410000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/420000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/430000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/440000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/450000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/460000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/470000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/480000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/490000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/500000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/510000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/520000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/530000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/540000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/550000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/560000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/570000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/580000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/590000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/600000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/610000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/620000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/630000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/640000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/650000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/660000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/670000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/680000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/690000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/700000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/710000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/720000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/730000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/740000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/750000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/760000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/770000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/780000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/790000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/800000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/810000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/820000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/830000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/840000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/850000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/860000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/870000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/880000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/890000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/900000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/910000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/920000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/930000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/940000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/950000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/960000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/970000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/980000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/990000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1000000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1010000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1020000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1030000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1040000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1050000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1060000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1070000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1080000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1090000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1100000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1110000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1120000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1130000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1140000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1150000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1160000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1170000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1180000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1190000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1200000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1210000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1220000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1230000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1240000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1250000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1260000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1270000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1280000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1290000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1300000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1310000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1320000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1330000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1340000\n",
      "Removing result: exp_local/offline/20250915061048/eval_result/1350000\n",
      "Removing model: exp_local/offline/20250915060737/models/1380000.pt\n",
      "Removing model: exp_local/offline/20250915060737/models/1390000.pt\n",
      "Removing model: exp_local/offline/20250915060737/models/1400000.pt\n",
      "Removing model: exp_local/offline/20250915060737/models/1410000.pt\n",
      "Removing model: exp_local/offline/20250915060737/models/1420000.pt\n",
      "Removing model: exp_local/offline/20250915060737/models/1430000.pt\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/0\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/10000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/20000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/30000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/40000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/50000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/60000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/70000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/80000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/90000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/100000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/110000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/120000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/130000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/140000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/150000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/160000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/170000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/180000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/190000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/200000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/210000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/220000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/230000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/240000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/250000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/260000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/270000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/280000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/290000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/300000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/310000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/320000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/330000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/340000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/350000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/360000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/370000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/380000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/390000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/400000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/410000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/420000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/430000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/440000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/450000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/460000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/470000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/480000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/490000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/500000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/510000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/520000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/530000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/540000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/550000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/560000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/570000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/580000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/590000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/600000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/610000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/620000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/630000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/640000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/650000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/660000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/670000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/680000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/690000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/700000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/710000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/720000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/730000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/740000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/750000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/760000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/770000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/780000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/790000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/800000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/810000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/820000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/830000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/840000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/850000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/860000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/870000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/880000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/890000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/900000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/910000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/920000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/930000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/940000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/950000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/960000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/970000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/980000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/990000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1000000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1010000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1020000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1030000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1040000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1050000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1060000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1070000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1080000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1090000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1100000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1110000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1120000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1130000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1140000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1150000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1160000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1170000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1180000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1190000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1200000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1210000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1220000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1230000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1240000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1250000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1260000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1270000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1280000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1290000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1300000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1310000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1320000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1330000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1340000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1350000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1360000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1370000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1380000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1390000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1400000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1410000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1420000\n",
      "Removing result: exp_local/offline/20250915060737/eval_result/1430000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "log_path = \"exp_local/offline\"\n",
    "\n",
    "for run_name in os.listdir(log_path):\n",
    "    run_path = os.path.join(log_path, run_name)\n",
    "    results_path = os.path.join(run_path, \"eval_result\")\n",
    "    models_path = os.path.join(run_path, \"models\")\n",
    "    models_list = os.listdir(models_path)\n",
    "    models_list.sort(key=lambda x: int(x.split('.')[0]))\n",
    "    for model_name in models_list[:-20]:\n",
    "        model_path = os.path.join(models_path, model_name)\n",
    "        print(f\"Removing model: {model_path}\")\n",
    "        os.remove(model_path)\n",
    "    results_list = os.listdir(results_path)\n",
    "    results_list.sort(key=lambda x: int(x))\n",
    "    for result_name in results_list[:-20]:\n",
    "        result_path = os.path.join(results_path, result_name)\n",
    "        print(f\"Removing result: {result_path}\")\n",
    "        shutil.rmtree(result_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ce9b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.ones(10)\n",
    "arg_max = np.argmax(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f38d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from url_benchmark.in_memory_hum_buffer import StepReplayBuffer, EpisodeBatch, ReplaySchema\n",
    "import numpy as np\n",
    "\n",
    "obs_horizon = 5\n",
    "discount = 0.96\n",
    "future = 0.98\n",
    "p_randomgoal = 0.375\n",
    "replay_buffer_max_step = 20\n",
    "discount = 0.96\n",
    "future = 0.98\n",
    "p_randomgoal = 0.375\n",
    "\n",
    "rep_schema = ReplaySchema(\n",
    "    obs_key=\"proprio\",\n",
    "    action_key=\"action\",\n",
    "    reward_key=\"reward\",\n",
    "    obs_horizon=obs_horizon,\n",
    "    cast_dtype=np.float32,\n",
    ")\n",
    "replay_buffer = StepReplayBuffer(\n",
    "    capacity_steps=replay_buffer_max_step,\n",
    "    schema=rep_schema,\n",
    "    discount=discount,\n",
    "    future=future,\n",
    "    p_randomgoal=p_randomgoal,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6711dc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cpfs/user/caozhe/workspace/HILP/hilp_zsrl/url_benchmark/in_memory_hum_buffer.py:358: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(path, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "replay_buffer = replay_buffer.load(\"/root/workspace/HILP/hilp_zsrl/exp_local/online/replay_buffer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a545a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10240846"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer._size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e43fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    episode_data = {\"proprio\": np.arange(0, 3), \"action\": np.random.randn(3, 2), \"reward\": np.random.randn(3)}\n",
    "    replay_buffer.add_episode(episode_data, {})\n",
    "replay_buffer._candidate_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f6dbc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([                  0,                   1,                   2,\n",
       "                         0,                   1,                   2,\n",
       "                         0,                   1,                   2,\n",
       "                         0,                   1,                   2,\n",
       "                         0,                   1,                   2,\n",
       "                         0,                   1,                   2,\n",
       "              472446402665, 8243102913262518282])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer._storage['proprio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "316a5bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_data = {\"proprio\": np.arange(99, 99+4), \"action\": np.random.randn(4, 2), \"reward\": np.random.randn(4)}\n",
    "replay_buffer.add_episode(episode_data, {})\n",
    "replay_buffer._candidate_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55722e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer.save(\"replay_buffer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db0d98e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cpfs/user/caozhe/workspace/HILP/hilp_zsrl/url_benchmark/in_memory_hum_buffer.py:358: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(path, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "new_buffer = StepReplayBuffer.load(\"replay_buffer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29e5e05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer._valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7a6fa28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_buffer._valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ff42ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from url_benchmark.humanoid_utils import plot_tripanel_heatmaps_with_line, calc_z_vector_matrixes, compute_global_color_limits\n",
    "\n",
    "test = np.random.randn(50, 10)\n",
    "goal_z_cosine_sim_list, goal_distance_list, goal_absdist_list = calc_z_vector_matrixes(test)\n",
    "plot_tripanel_heatmaps_with_line(goal_z_cosine_sim_list, goal_distance_list, goal_absdist_list, [f\"latent_space_distance_g={goal_distance_list[g_idx].shape[-1]}.png\" for g_idx in range(len(goal_distance_list))], \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1ef5b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1032154/4184490847.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  payload = torch.load(pt_path)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on CUDA device 2 but torch.cuda.device_count() is 2. Please use torch.load with map_location to map your storages to an existing device.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m pt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/root/workspace/HILP/hilp_zsrl/exp_local/pr0.375_phi_exp0.5_phi_g0.96_False_mix0.5_False_256_collected_single_short_phih1024_state_sacTrue_hor5_rszFalse/20250909124712/models/1040000.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m payload \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpt_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hilp_zsrl/lib/python3.8/site-packages/torch/serialization.py:1097\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1096\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1097\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1105\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/hilp_zsrl/lib/python3.8/site-packages/torch/serialization.py:1525\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# Needed for tensors where storage device and rebuild tensor device are\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# not connected (wrapper subclasses and tensors rebuilt using numpy)\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_thread_local_state\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[0;32m-> 1525\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_thread_local_state\u001b[38;5;241m.\u001b[39mmap_location\n\u001b[1;32m   1528\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[0;32m~/miniconda3/envs/hilp_zsrl/lib/python3.8/site-packages/torch/serialization.py:1492\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1491\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1492\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/hilp_zsrl/lib/python3.8/site-packages/torch/serialization.py:1466\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1461\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1465\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1466\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1467\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1468\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1471\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/hilp_zsrl/lib/python3.8/site-packages/torch/serialization.py:414\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 414\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/hilp_zsrl/lib/python3.8/site-packages/torch/serialization.py:391\u001b[0m, in \u001b[0;36m_deserialize\u001b[0;34m(backend_name, obj, location)\u001b[0m\n\u001b[1;32m    389\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_privateuse1_backend_name()\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(backend_name):\n\u001b[0;32m--> 391\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/hilp_zsrl/lib/python3.8/site-packages/torch/serialization.py:372\u001b[0m, in \u001b[0;36m_validate_device\u001b[0;34m(location, backend_name)\u001b[0m\n\u001b[1;32m    370\u001b[0m     device_count \u001b[38;5;241m=\u001b[39m device_module\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n\u001b[0;32m--> 372\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m device \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    373\u001b[0m                            \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but torch.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.device_count() is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    374\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease use torch.load with map_location to map your storages \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    375\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto an existing device.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m device\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on CUDA device 2 but torch.cuda.device_count() is 2. Please use torch.load with map_location to map your storages to an existing device."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "pt_path = \"/root/workspace/HILP/hilp_zsrl/exp_local/pr0.375_phi_exp0.5_phi_g0.96_False_mix0.5_False_256_collected_single_short_phih1024_state_sacTrue_hor5_rszFalse/20250909124712/models/1040000.pt\"\n",
    "\n",
    "payload = torch.load(pt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2377d35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('running_mean',\n",
       "              tensor([ 2.0147e-02,  6.0220e-01,  2.5520e-01,  2.2867e+00, -1.6187e-02,\n",
       "                      -5.7289e-02, -8.5198e-01,  1.1617e-03, -5.2512e-01,  3.3111e-01,\n",
       "                       1.3118e+00,  1.0967e+00,  6.3422e-02,  8.0338e-03, -1.2739e+00,\n",
       "                       2.5497e+00,  1.9941e-02,  7.0307e-03,  1.9994e+00,  5.2392e-01,\n",
       "                       3.3466e-02, -4.3577e-02,  7.6524e-03, -4.5467e-02,  1.0872e-01,\n",
       "                       7.9773e-02, -2.2171e-02,  1.3644e-01,  1.2087e-02, -4.5943e+00,\n",
       "                       8.9028e-01, -4.4692e-02,  3.7790e-02, -5.9837e-01, -1.9326e+00,\n",
       "                       1.2736e+00,  5.4615e-02,  3.2852e-02,  7.9311e-01, -1.0502e-03,\n",
       "                      -1.2139e-02,  6.6157e-01,  3.9624e-02, -1.7618e-02, -4.3989e-02,\n",
       "                       4.6994e-01, -7.7827e-03, -3.9851e-02, -7.6388e-03, -1.5477e-01,\n",
       "                      -2.5043e-01,  2.0338e+00,  7.3412e-01,  7.1308e-02,  1.5255e+00,\n",
       "                       1.7558e-03,  1.3708e+00, -3.2389e-02, -2.8606e-03, -1.7404e+00,\n",
       "                       8.1416e-02,  5.9563e-02, -2.8440e-02,  2.3410e+00,  1.5529e-01,\n",
       "                      -1.1130e-01,  5.6354e-01, -5.5213e-02, -1.1170e-01, -2.8204e-02,\n",
       "                      -1.0760e-02, -7.2978e-02, -1.1773e-02,  4.7063e-02,  3.3485e-02,\n",
       "                       9.2615e-02, -7.1009e-01,  4.2804e-01,  2.7192e+00,  6.8189e-01,\n",
       "                       4.6769e-01, -6.8786e-01,  9.7280e-02,  2.8897e-03,  2.2758e+00,\n",
       "                      -1.9598e+00, -7.3359e-02,  2.3262e+00,  4.6176e-02, -5.3196e-02,\n",
       "                       9.1040e-03,  3.1048e-02, -6.6669e-02, -4.2866e-02, -2.7911e+00,\n",
       "                      -1.0257e-01, -2.4298e-02,  1.7876e-02,  3.4867e-02, -6.1601e-02,\n",
       "                      -4.3483e-02, -6.1468e-03,  4.0621e-02,  3.6178e-02,  3.1953e+00,\n",
       "                      -5.9692e-02,  3.5362e-02,  8.8189e-02,  2.4019e-02, -1.1128e-02,\n",
       "                      -5.8976e-02,  2.0730e-02, -5.6375e-03, -3.7541e-02,  3.3886e-02,\n",
       "                       8.4308e-02, -6.1292e-01,  1.5548e-02, -8.3718e-04, -1.7688e-01,\n",
       "                       6.9650e-01, -6.0787e-02, -4.0707e-02,  6.6494e-02,  2.5908e-02,\n",
       "                      -2.8892e-02,  2.3975e-03, -5.4442e-02,  4.8849e-03,  1.3652e-02,\n",
       "                       1.6502e+00, -8.5962e-03, -1.1686e+00, -1.5250e-02, -8.1023e-01,\n",
       "                      -1.4505e-02,  1.1707e+00, -9.2157e-02,  4.1722e-01,  1.6619e-02,\n",
       "                       4.7949e-02,  1.9073e-01,  6.9611e-03, -1.4459e+00, -2.8941e-02,\n",
       "                       3.2498e-02, -8.8855e-02, -1.4189e+00,  4.6954e-02,  1.0251e+01,\n",
       "                       2.1894e-01, -6.4941e-02, -5.4107e-02, -8.1752e-04,  4.2439e-01,\n",
       "                       1.1901e+00, -4.0968e-03, -9.3003e-03,  5.1028e-01,  1.0758e-02,\n",
       "                       4.4785e+00,  2.6193e+00, -7.0537e-02,  1.8554e-02, -1.0524e-01,\n",
       "                      -1.5997e+00, -3.5190e-03, -4.2836e-02,  4.8962e-02, -5.3649e-01,\n",
       "                      -9.0542e-03, -1.1779e-02, -8.6170e-03, -6.4341e-02, -2.4100e-01,\n",
       "                      -7.6767e-02, -9.4425e-03, -1.0260e-01,  2.5337e-02, -6.8537e-01,\n",
       "                      -8.9074e-02, -1.3817e+00,  1.3696e+00, -2.3580e-01,  2.3784e-02,\n",
       "                      -6.7866e-02,  2.8056e-02, -2.4935e-03,  6.7940e-01, -2.0570e-02,\n",
       "                      -3.5863e-03, -2.6222e+00,  8.1502e-02, -1.2591e-01,  5.6603e+00,\n",
       "                      -6.2670e-02,  8.1988e+00, -7.3167e-01, -4.7682e-01,  4.7796e-02,\n",
       "                      -8.2567e-01, -1.0829e+00,  4.4724e-03,  1.6103e-01, -1.4963e+00,\n",
       "                       2.3445e-02,  2.3462e-02, -1.9329e-02,  8.5172e-02, -1.8856e-02,\n",
       "                       1.1597e+00, -3.0755e-03,  1.2521e+00,  5.9207e-01,  1.8257e+00,\n",
       "                      -7.8373e-02, -2.3428e-02, -1.0719e+01,  3.7152e-02,  3.3865e-01,\n",
       "                       4.0833e-02, -4.9944e-01, -2.6779e-01, -2.4462e+00,  2.6875e-01,\n",
       "                      -6.5354e-02,  8.0807e-01,  1.5897e+00,  9.3741e-02, -6.3435e-03,\n",
       "                       3.7262e-02,  1.9776e+00,  3.1302e-01, -7.3625e-03,  7.5814e-03,\n",
       "                       4.4217e-02, -1.3995e-01,  4.3659e-02,  6.9112e-01,  8.4075e-01,\n",
       "                      -2.1823e+00,  6.8227e-02, -1.2263e-01,  5.7983e-01, -4.6858e-01,\n",
       "                       7.6132e-02, -6.9389e-01, -1.2905e-02,  1.0201e-01, -1.2515e-01,\n",
       "                      -7.3535e-02, -2.5366e-02,  5.3462e-01, -4.3255e-01, -5.7636e-03,\n",
       "                       2.5166e-02])),\n",
       "             ('running_std',\n",
       "              tensor([0.1038, 1.8649, 1.3809, 1.7969, 0.0973, 0.3230, 1.6319, 0.1026, 1.5268,\n",
       "                      0.4913, 1.5705, 1.9069, 0.0987, 0.1088, 1.2692, 1.9629, 0.1003, 0.0853,\n",
       "                      1.5785, 0.8296, 0.0946, 0.1076, 0.0961, 0.0998, 0.1049, 0.0961, 0.0858,\n",
       "                      1.8553, 0.1031, 2.1162, 1.4183, 0.0947, 0.1047, 1.8666, 1.3263, 1.4802,\n",
       "                      1.6041, 0.0921, 1.6351, 0.0975, 0.0961, 1.7176, 0.0946, 0.0874, 0.0980,\n",
       "                      1.8819, 0.0991, 0.0929, 0.0981, 1.5903, 0.5070, 1.8311, 2.0419, 0.0930,\n",
       "                      1.5018, 0.0972, 1.5289, 0.0993, 0.0866, 1.2811, 0.1024, 0.0941, 0.1013,\n",
       "                      1.1375, 0.0982, 0.0899, 2.0174, 0.0962, 0.4920, 0.0777, 0.0923, 0.0946,\n",
       "                      0.0938, 0.1004, 0.0901, 0.3136, 1.6080, 1.7101, 1.8966, 1.6646, 1.6407,\n",
       "                      1.6783, 0.0919, 0.0850, 1.8435, 1.7450, 0.0909, 1.5530, 0.0875, 0.0917,\n",
       "                      0.1078, 0.1106, 0.0959, 0.0919, 1.8823, 0.0901, 1.8291, 0.0898, 0.0965,\n",
       "                      0.0986, 0.1041, 0.0928, 0.1023, 0.0949, 1.8646, 0.0969, 0.0978, 0.0888,\n",
       "                      0.1127, 0.0983, 1.6884, 0.0856, 1.9928, 0.0987, 0.0852, 0.0981, 1.1995,\n",
       "                      0.0914, 0.0946, 0.2444, 1.5779, 0.1014, 0.0989, 0.0906, 0.0928, 0.0964,\n",
       "                      0.0978, 0.0925, 0.0804, 0.1084, 1.8423, 0.0963, 1.7725, 0.0927, 1.0189,\n",
       "                      0.1012, 1.5715, 0.1009, 0.9434, 0.0860, 0.0874, 1.3544, 0.0958, 1.6381,\n",
       "                      1.1607, 0.1047, 0.0980, 1.6354, 0.1041, 2.3427, 1.9291, 0.1065, 0.0955,\n",
       "                      0.0846, 0.8666, 1.4410, 0.1000, 0.1108, 1.1518, 0.1004, 2.2385, 1.6290,\n",
       "                      0.0971, 0.0906, 0.0881, 1.5189, 0.0912, 0.1025, 0.0979, 0.8465, 0.0864,\n",
       "                      0.1019, 0.0864, 0.0995, 1.1784, 0.1055, 0.0903, 0.0862, 0.0963, 1.7151,\n",
       "                      0.1023, 1.4495, 1.4163, 1.2234, 0.0979, 0.1014, 0.1027, 0.0906, 1.5885,\n",
       "                      0.0922, 0.1040, 2.1080, 0.0824, 0.2848, 1.9662, 0.0878, 2.4018, 1.7965,\n",
       "                      1.6512, 0.1021, 1.3896, 0.9216, 0.0918, 0.9215, 1.9476, 0.0883, 0.0987,\n",
       "                      0.1089, 0.0991, 0.0940, 1.4992, 0.0999, 1.7607, 0.7705, 1.9695, 0.1073,\n",
       "                      0.1037, 2.5210, 0.0888, 1.6979, 0.0861, 0.7700, 1.7940, 1.6468, 0.2858,\n",
       "                      0.1018, 1.1634, 1.3469, 0.9935, 0.0883, 0.0978, 1.4723, 0.2660, 0.0891,\n",
       "                      0.0956, 0.0934, 1.2138, 0.0834, 1.5629, 1.7822, 1.3683, 0.0981, 1.8095,\n",
       "                      1.4855, 1.3481, 0.0940, 1.8937, 0.0947, 0.1013, 1.1829, 0.0887, 0.0984,\n",
       "                      2.0099, 1.8513, 0.2010, 0.0926])),\n",
       "             ('feature_net.0.weight',\n",
       "              tensor([[-0.0425, -0.0294, -0.0284,  ...,  0.0119, -0.0099, -0.0322],\n",
       "                      [-0.0008,  0.0569, -0.0215,  ...,  0.0332, -0.0456, -0.0249],\n",
       "                      [-0.0100, -0.0368, -0.0020,  ...,  0.0156, -0.0237, -0.0193],\n",
       "                      ...,\n",
       "                      [ 0.0179, -0.0100, -0.0375,  ...,  0.0092, -0.0081,  0.0264],\n",
       "                      [ 0.0091, -0.0526, -0.0149,  ..., -0.0077,  0.0898, -0.0833],\n",
       "                      [-0.0454,  0.0326, -0.0377,  ...,  0.0460,  0.0079,  0.0658]])),\n",
       "             ('feature_net.0.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])),\n",
       "             ('feature_net.1.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])),\n",
       "             ('feature_net.1.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])),\n",
       "             ('feature_net.3.weight',\n",
       "              tensor([[-0.0208,  0.0139,  0.0232,  ..., -0.0046,  0.0103, -0.0057],\n",
       "                      [-0.0379, -0.0125, -0.0078,  ...,  0.0007,  0.0483, -0.0250],\n",
       "                      [ 0.0018, -0.0239, -0.0289,  ..., -0.0445, -0.0561, -0.0346],\n",
       "                      ...,\n",
       "                      [ 0.0260,  0.0264, -0.0010,  ...,  0.0188, -0.0067, -0.0354],\n",
       "                      [-0.0053,  0.0043,  0.0567,  ..., -0.0149, -0.0488,  0.0348],\n",
       "                      [ 0.0147,  0.0122,  0.0068,  ..., -0.0024, -0.0321, -0.0217]])),\n",
       "             ('feature_net.3.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])),\n",
       "             ('feature_net.5.weight',\n",
       "              tensor([[-0.0162,  0.0077, -0.0305,  ..., -0.0291, -0.0421,  0.0577],\n",
       "                      [ 0.0204, -0.0157, -0.0172,  ...,  0.0071,  0.0590,  0.0248],\n",
       "                      [ 0.0282, -0.0090, -0.0210,  ...,  0.0361, -0.0285,  0.0516],\n",
       "                      ...,\n",
       "                      [ 0.0142, -0.0103,  0.0051,  ..., -0.0069,  0.0160, -0.0343],\n",
       "                      [ 0.0131, -0.0117, -0.0126,  ...,  0.0044, -0.0013, -0.0360],\n",
       "                      [-0.0087,  0.0007, -0.0131,  ...,  0.0296,  0.0090, -0.0606]])),\n",
       "             ('feature_net.5.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('phi1.0.weight',\n",
       "              tensor([[-3.3297,  0.4075, -0.4781,  ...,  0.8303, -0.0339, -0.8896],\n",
       "                      [ 0.7973,  0.3279,  0.0129,  ..., -0.0133, -0.1765, -0.3008],\n",
       "                      [ 0.2003,  0.0270,  0.4909,  ...,  0.0311,  0.0164, -0.1509],\n",
       "                      ...,\n",
       "                      [-0.5937, -0.3371,  0.2162,  ...,  0.1839,  0.0862,  0.0104],\n",
       "                      [-0.0208, -0.0997,  0.9738,  ...,  0.2663,  0.1232,  0.1520],\n",
       "                      [-0.0436, -0.2490, -0.1613,  ..., -0.0888, -0.5849,  0.1377]])),\n",
       "             ('phi1.0.bias',\n",
       "              tensor([-0.1236, -0.1106, -0.2971,  ...,  0.1579, -0.4057,  0.2264])),\n",
       "             ('phi1.1.weight',\n",
       "              tensor([-7.2053e-04,  1.8962e+00,  1.9763e+00,  ...,  4.8146e-02,\n",
       "                       1.1153e+00,  3.5192e-01])),\n",
       "             ('phi1.1.bias',\n",
       "              tensor([-9.3464e-04,  1.7926e+00,  3.0460e-01,  ..., -2.7500e-03,\n",
       "                       1.8901e-02, -2.7614e-01])),\n",
       "             ('phi1.3.weight',\n",
       "              tensor([[ 0.0089,  0.0432,  0.2110,  ...,  0.0840,  0.1203,  0.4955],\n",
       "                      [-0.2782, -0.2301, -0.6944,  ..., -0.3730, -0.7513,  0.2037],\n",
       "                      [ 0.0598,  0.2690, -0.2623,  ..., -0.0708, -0.6304,  0.2313],\n",
       "                      ...,\n",
       "                      [ 0.1050, -0.0666,  0.1379,  ...,  0.9645, -1.6311, -0.0084],\n",
       "                      [ 0.0460, -0.2598, -0.4827,  ...,  0.4243,  0.3110,  0.0323],\n",
       "                      [ 0.2317,  0.7212, -0.2430,  ..., -0.3309,  0.5587, -0.1097]])),\n",
       "             ('phi1.3.bias',\n",
       "              tensor([-0.4685,  0.1744, -0.1427,  ..., -0.0738,  0.2626,  0.0771])),\n",
       "             ('phi1.4.weight',\n",
       "              tensor([ 2.2888e+00, -7.7211e-04,  4.8077e-02,  ..., -2.4382e-03,\n",
       "                       9.5701e-01,  3.3692e-03])),\n",
       "             ('phi1.4.bias',\n",
       "              tensor([-1.2479e+00, -7.2479e-04,  5.0078e-03,  ..., -2.6014e-03,\n",
       "                      -2.5982e-01, -1.0468e-03])),\n",
       "             ('phi1.6.weight',\n",
       "              tensor([[ 0.0121, -0.0780, -0.0384,  ..., -0.0359,  0.0292,  0.1076],\n",
       "                      [ 0.0612, -0.0050,  0.0430,  ...,  0.0346, -0.0037, -0.0334],\n",
       "                      [ 0.0421, -0.0312, -0.0509,  ..., -0.0372, -0.0243,  0.0081],\n",
       "                      ...,\n",
       "                      [ 0.0159, -0.0336, -0.0427,  ...,  0.0651,  0.0237,  0.0124],\n",
       "                      [ 0.2061, -0.0943,  0.6238,  ..., -0.0946,  0.4597,  0.1753],\n",
       "                      [ 0.0392, -0.0279,  0.0539,  ...,  0.0343, -0.0193,  0.0490]])),\n",
       "             ('phi1.6.bias',\n",
       "              tensor([-0.0407, -0.0198, -0.0497,  ..., -0.0164, -0.4154, -0.0548])),\n",
       "             ('phi1.8.weight',\n",
       "              tensor([[ 0.0326, -0.0376,  0.0096,  ..., -0.0739,  0.0041,  0.0423],\n",
       "                      [ 0.0630,  0.0109,  0.0073,  ..., -0.0458,  0.0258,  0.0371],\n",
       "                      [-0.0346,  0.0169, -0.0362,  ...,  0.0325,  0.0092, -0.0416],\n",
       "                      ...,\n",
       "                      [-0.0389, -0.0120, -0.0553,  ..., -0.0028,  0.0028,  0.0466],\n",
       "                      [-0.0825,  0.0176,  0.0366,  ..., -0.0039, -0.1189,  0.0003],\n",
       "                      [ 0.0472,  0.0219,  0.0067,  ..., -0.0550, -0.0649, -0.0484]])),\n",
       "             ('phi1.8.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('phi2.0.weight',\n",
       "              tensor([[ 0.1739, -0.1584,  0.0015,  ..., -0.1330,  0.0359,  0.1423],\n",
       "                      [-0.2504, -0.3061, -0.0351,  ..., -0.1411, -0.0077, -0.2914],\n",
       "                      [ 0.1665,  0.0664,  0.0979,  ..., -0.1077,  0.1812, -0.1836],\n",
       "                      ...,\n",
       "                      [ 0.8626,  0.4838, -0.0085,  ...,  0.1146,  0.0104, -0.0095],\n",
       "                      [-0.0086,  0.2783,  0.0378,  ..., -0.0709, -0.1421,  0.1070],\n",
       "                      [-0.3378,  0.1116,  0.1912,  ..., -0.4055, -0.2196,  0.1257]])),\n",
       "             ('phi2.0.bias',\n",
       "              tensor([-0.0153, -0.3338,  0.2406,  ..., -0.0609, -0.2927, -0.1911])),\n",
       "             ('phi2.1.weight',\n",
       "              tensor([1.9297, 1.2261, 1.6456,  ..., 1.1655, 1.6341, 2.3523])),\n",
       "             ('phi2.1.bias',\n",
       "              tensor([-0.4536, -1.2078,  0.0565,  ...,  0.1612,  0.8247,  0.5123])),\n",
       "             ('phi2.3.weight',\n",
       "              tensor([[ 0.1699,  0.0210, -0.0677,  ...,  0.6023,  0.0214,  0.5091],\n",
       "                      [-0.5707,  0.0269, -0.1402,  ..., -0.0507, -0.3715, -0.1071],\n",
       "                      [-0.1180, -0.1230,  0.9933,  ..., -0.2146,  0.0021, -0.1745],\n",
       "                      ...,\n",
       "                      [-0.0368,  0.1438,  0.2923,  ..., -0.1841, -0.3412,  0.0093],\n",
       "                      [ 0.2584,  0.5918,  0.3778,  ..., -0.3932,  0.5796, -0.4879],\n",
       "                      [-0.5787,  0.5840, -0.9769,  ..., -0.1786, -1.3662,  0.5544]])),\n",
       "             ('phi2.3.bias',\n",
       "              tensor([ 0.6636, -0.0110,  0.0597,  ...,  0.0719,  0.1450,  0.1766])),\n",
       "             ('phi2.4.weight',\n",
       "              tensor([ 0.7158,  0.0973,  0.4546,  ...,  0.0113,  0.0013, -0.0035])),\n",
       "             ('phi2.4.bias',\n",
       "              tensor([-3.8431e-02,  1.5501e-03,  3.3793e-01,  ...,  1.3580e-03,\n",
       "                      -6.2712e-05,  5.8123e-04])),\n",
       "             ('phi2.6.weight',\n",
       "              tensor([[ 0.5025,  0.2092, -0.1658,  ...,  0.0144,  0.0240,  0.0042],\n",
       "                      [ 0.1776, -0.2700,  0.1232,  ..., -0.4320,  0.0423,  0.4365],\n",
       "                      [-0.0581,  0.0337,  0.0327,  ...,  0.0387,  0.0756,  0.0512],\n",
       "                      ...,\n",
       "                      [-0.7168,  0.4040, -0.5498,  ..., -0.0248, -0.0379,  0.0303],\n",
       "                      [-0.0347, -0.0530,  0.0161,  ...,  0.0011,  0.0212,  0.0234],\n",
       "                      [-0.0951,  0.0643, -0.0752,  ...,  0.1587,  0.0391,  0.0131]])),\n",
       "             ('phi2.6.bias',\n",
       "              tensor([-0.2315, -0.2155, -0.0590,  ..., -0.1622, -0.0314, -0.4019])),\n",
       "             ('phi2.8.weight',\n",
       "              tensor([[-0.0279, -0.0003,  0.0656,  ..., -0.0405,  0.0025, -0.0420],\n",
       "                      [-0.0031, -0.0228, -0.0138,  ...,  0.0045,  0.0524, -0.0092],\n",
       "                      [-0.0382,  0.0105, -0.0437,  ..., -0.0123, -0.0228,  0.0658],\n",
       "                      ...,\n",
       "                      [ 0.1041,  0.1373,  0.0195,  ...,  0.0502, -0.0160, -0.0421],\n",
       "                      [-0.0074, -0.0171,  0.0322,  ..., -0.0015, -0.0266, -0.0370],\n",
       "                      [ 0.0023,  0.0079, -0.0231,  ..., -0.0013,  0.0086,  0.0160]])),\n",
       "             ('phi2.8.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('target_phi1.0.weight',\n",
       "              tensor([[-3.3315,  0.4041, -0.4824,  ...,  0.8382, -0.0320, -0.8909],\n",
       "                      [ 0.8000,  0.3240,  0.0167,  ..., -0.0102, -0.1683, -0.3011],\n",
       "                      [ 0.1977,  0.0331,  0.4955,  ...,  0.0319,  0.0154, -0.1569],\n",
       "                      ...,\n",
       "                      [-0.5941, -0.3352,  0.2152,  ...,  0.1890,  0.0855,  0.0061],\n",
       "                      [-0.0211, -0.0994,  0.9740,  ...,  0.2758,  0.1214,  0.1530],\n",
       "                      [-0.0421, -0.2538, -0.1614,  ..., -0.0907, -0.5817,  0.1355]])),\n",
       "             ('target_phi1.0.bias',\n",
       "              tensor([-0.1221, -0.1104, -0.2950,  ...,  0.1573, -0.4080,  0.2266])),\n",
       "             ('target_phi1.1.weight',\n",
       "              tensor([-1.4933e-03,  1.8952e+00,  1.9803e+00,  ...,  5.1580e-02,\n",
       "                       1.1163e+00,  3.5260e-01])),\n",
       "             ('target_phi1.1.bias',\n",
       "              tensor([-1.3278e-03,  1.7936e+00,  3.0663e-01,  ..., -2.2952e-03,\n",
       "                       1.6404e-02, -2.7602e-01])),\n",
       "             ('target_phi1.3.weight',\n",
       "              tensor([[ 0.0164,  0.0423,  0.2102,  ...,  0.0803,  0.1191,  0.4928],\n",
       "                      [-0.2777, -0.2313, -0.6939,  ..., -0.3711, -0.7499,  0.2022],\n",
       "                      [ 0.0537,  0.2693, -0.2620,  ..., -0.0715, -0.6313,  0.2333],\n",
       "                      ...,\n",
       "                      [ 0.1052, -0.0670,  0.1369,  ...,  0.9680, -1.6298, -0.0076],\n",
       "                      [ 0.0465, -0.2584, -0.4828,  ...,  0.4222,  0.3153,  0.0351],\n",
       "                      [ 0.2268,  0.7218, -0.2441,  ..., -0.3259,  0.5581, -0.1145]])),\n",
       "             ('target_phi1.3.bias',\n",
       "              tensor([-0.4692,  0.1744, -0.1418,  ..., -0.0734,  0.2641,  0.0771])),\n",
       "             ('target_phi1.4.weight',\n",
       "              tensor([2.2870e+00, 7.3961e-04, 4.9712e-02,  ..., 6.7776e-04, 9.5860e-01,\n",
       "                      9.1197e-05])),\n",
       "             ('target_phi1.4.bias',\n",
       "              tensor([-1.2481e+00,  3.1230e-05,  6.4643e-03,  ..., -1.7030e-04,\n",
       "                      -2.5808e-01, -3.7780e-04])),\n",
       "             ('target_phi1.6.weight',\n",
       "              tensor([[ 0.0121, -0.0780, -0.0384,  ..., -0.0359,  0.0292,  0.1076],\n",
       "                      [ 0.0612, -0.0050,  0.0430,  ...,  0.0346, -0.0037, -0.0334],\n",
       "                      [ 0.0421, -0.0312, -0.0509,  ..., -0.0372, -0.0243,  0.0081],\n",
       "                      ...,\n",
       "                      [ 0.0159, -0.0336, -0.0427,  ...,  0.0651,  0.0237,  0.0124],\n",
       "                      [ 0.2061, -0.0943,  0.6238,  ..., -0.0946,  0.4597,  0.1753],\n",
       "                      [ 0.0392, -0.0279,  0.0539,  ...,  0.0343, -0.0193,  0.0490]])),\n",
       "             ('target_phi1.6.bias',\n",
       "              tensor([-0.0407, -0.0198, -0.0497,  ..., -0.0164, -0.4154, -0.0548])),\n",
       "             ('target_phi1.8.weight',\n",
       "              tensor([[ 0.0326, -0.0376,  0.0096,  ..., -0.0739,  0.0041,  0.0423],\n",
       "                      [ 0.0630,  0.0109,  0.0073,  ..., -0.0458,  0.0258,  0.0371],\n",
       "                      [-0.0346,  0.0169, -0.0362,  ...,  0.0325,  0.0092, -0.0416],\n",
       "                      ...,\n",
       "                      [-0.0389, -0.0120, -0.0553,  ..., -0.0028,  0.0028,  0.0466],\n",
       "                      [-0.0826,  0.0176,  0.0366,  ..., -0.0039, -0.1189,  0.0003],\n",
       "                      [ 0.0472,  0.0219,  0.0067,  ..., -0.0550, -0.0649, -0.0484]])),\n",
       "             ('target_phi1.8.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('target_phi2.0.weight',\n",
       "              tensor([[ 0.1733, -0.1526,  0.0069,  ..., -0.1310,  0.0276,  0.1453],\n",
       "                      [-0.2496, -0.3052, -0.0315,  ..., -0.1451, -0.0072, -0.2947],\n",
       "                      [ 0.1648,  0.0672,  0.0988,  ..., -0.1073,  0.1766, -0.1822],\n",
       "                      ...,\n",
       "                      [ 0.8652,  0.4869, -0.0127,  ...,  0.1160,  0.0092, -0.0098],\n",
       "                      [-0.0139,  0.2734,  0.0399,  ..., -0.0803, -0.1321,  0.1037],\n",
       "                      [-0.3378,  0.1132,  0.1884,  ..., -0.4085, -0.2251,  0.1242]])),\n",
       "             ('target_phi2.0.bias',\n",
       "              tensor([-0.0143, -0.3348,  0.2405,  ..., -0.0597, -0.2859, -0.1918])),\n",
       "             ('target_phi2.1.weight',\n",
       "              tensor([1.9278, 1.2254, 1.6478,  ..., 1.1668, 1.6356, 2.3537])),\n",
       "             ('target_phi2.1.bias',\n",
       "              tensor([-0.4537, -1.2079,  0.0567,  ...,  0.1629,  0.8309,  0.5109])),\n",
       "             ('target_phi2.3.weight',\n",
       "              tensor([[ 1.6874e-01,  2.0366e-02, -6.8306e-02,  ...,  6.0174e-01,\n",
       "                        2.1652e-02,  5.0960e-01],\n",
       "                      [-5.7233e-01,  2.2137e-02, -1.3824e-01,  ..., -4.5869e-02,\n",
       "                       -3.6898e-01, -1.0634e-01],\n",
       "                      [-1.1877e-01, -1.2366e-01,  9.9557e-01,  ..., -2.1457e-01,\n",
       "                        4.2896e-04, -1.7483e-01],\n",
       "                      ...,\n",
       "                      [-3.4186e-02,  1.4743e-01,  2.9831e-01,  ..., -1.8755e-01,\n",
       "                       -3.4378e-01,  1.0766e-02],\n",
       "                      [ 2.5777e-01,  5.9177e-01,  3.7742e-01,  ..., -3.9818e-01,\n",
       "                        5.7923e-01, -4.8790e-01],\n",
       "                      [-5.7482e-01,  5.8443e-01, -9.8212e-01,  ..., -1.7663e-01,\n",
       "                       -1.3678e+00,  5.5483e-01]])),\n",
       "             ('target_phi2.3.bias',\n",
       "              tensor([ 0.6641, -0.0100,  0.0593,  ...,  0.0706,  0.1452,  0.1758])),\n",
       "             ('target_phi2.4.weight',\n",
       "              tensor([ 7.1471e-01,  9.8363e-02,  4.5503e-01,  ...,  1.5887e-02,\n",
       "                       6.1960e-04, -1.6156e-03])),\n",
       "             ('target_phi2.4.bias',\n",
       "              tensor([-3.7966e-02,  1.9407e-03,  3.3683e-01,  ...,  5.9172e-06,\n",
       "                       2.6072e-04, -1.4683e-05])),\n",
       "             ('target_phi2.6.weight',\n",
       "              tensor([[ 0.5047,  0.2022, -0.1610,  ...,  0.0159,  0.0261,  0.0073],\n",
       "                      [ 0.1776, -0.2700,  0.1232,  ..., -0.4320,  0.0423,  0.4365],\n",
       "                      [-0.0581,  0.0337,  0.0327,  ...,  0.0387,  0.0756,  0.0512],\n",
       "                      ...,\n",
       "                      [-0.7140,  0.4065, -0.5486,  ..., -0.0285, -0.0373,  0.0278],\n",
       "                      [-0.0347, -0.0530,  0.0161,  ...,  0.0011,  0.0212,  0.0234],\n",
       "                      [-0.0975,  0.0685, -0.0723,  ...,  0.1601,  0.0336,  0.0136]])),\n",
       "             ('target_phi2.6.bias',\n",
       "              tensor([-0.2314, -0.2155, -0.0590,  ..., -0.1633, -0.0314, -0.4009])),\n",
       "             ('target_phi2.8.weight',\n",
       "              tensor([[-0.0243, -0.0003,  0.0656,  ..., -0.0407,  0.0025, -0.0436],\n",
       "                      [-0.0010, -0.0228, -0.0138,  ...,  0.0048,  0.0524, -0.0099],\n",
       "                      [-0.0380,  0.0105, -0.0437,  ..., -0.0121, -0.0228,  0.0626],\n",
       "                      ...,\n",
       "                      [ 0.1024,  0.1373,  0.0195,  ...,  0.0442, -0.0160, -0.0396],\n",
       "                      [-0.0052, -0.0171,  0.0322,  ..., -0.0098, -0.0266, -0.0394],\n",
       "                      [ 0.0040,  0.0079, -0.0231,  ...,  0.0006,  0.0086,  0.0176]])),\n",
       "             ('target_phi2.8.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload['agent'].feature_learner.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "573e6b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload._episodes_length[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65238284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['agent', 'global_step', 'global_episode'])\n",
      "<url_benchmark.agent.sf.SFAgent object at 0x7efa9eb02220>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_455176/4288144180.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  payload = torch.load(f)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "ckpt_path = \"/root/workspace/HILP/hilp_zsrl/exp_local/sf_h1int_0.98_f0.99_pr0.375_phi_exp0.5_phi_g0.96_qlFalse_False_mix0.5_False_512_collected_single_short_phih2048_state/20250908103821/models/520000.pt\"\n",
    "with open(ckpt_path, 'rb') as f:\n",
    "    payload = torch.load(f)\n",
    "\n",
    "print(payload.keys())\n",
    "print(payload['agent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570ba590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('running_mean',\n",
       "              tensor([ 4.9263e-02, -3.3308e-01,  4.6538e-02, -8.5039e-03, -2.3981e-02,\n",
       "                      -9.2834e-02, -3.2790e-03,  4.1932e-02, -5.2947e-02,  3.7770e-01,\n",
       "                       1.0527e+00,  3.1044e+00, -1.1646e-02,  4.1144e-02, -2.0607e-02,\n",
       "                       7.7021e+00,  1.2694e-01,  2.0665e+00,  2.3742e-02,  2.4466e+00,\n",
       "                      -1.8919e-02, -8.3937e-02,  6.5327e-03,  1.0447e-01, -3.5178e-02,\n",
       "                       9.8109e-02,  3.9984e+00, -1.0578e-01, -1.3239e+00,  3.0720e-02,\n",
       "                       1.0095e-02,  8.4214e-02,  1.4523e-02, -4.3836e-02,  5.5517e-02,\n",
       "                      -4.6555e-02, -4.0819e-02,  7.9044e-03, -4.1037e-02, -2.9813e-02,\n",
       "                       9.1508e-01,  3.3952e-02, -6.9857e-02, -1.2653e+00, -1.4300e+00,\n",
       "                       1.2560e+00,  1.9915e+00,  2.4585e-02, -5.1354e-01,  7.7444e-02,\n",
       "                       1.0205e+00,  9.8395e-04,  4.5235e-02,  1.6474e-03, -4.0606e-04,\n",
       "                      -3.3109e-02, -4.8816e-02, -3.2307e-01,  5.9067e-02, -8.6976e-01,\n",
       "                      -4.8968e-02, -9.5366e-02,  7.0144e-02, -6.3898e-03, -1.3148e-02,\n",
       "                       1.2785e-03,  1.2128e-03, -5.4444e-02,  4.3045e-01, -6.6641e-03,\n",
       "                       3.3416e-02, -1.3408e-03, -5.7522e-03,  6.8639e-02,  3.0970e-02,\n",
       "                      -9.3428e-02,  3.5069e-02,  2.5403e-02, -6.4613e-06,  8.3228e-02,\n",
       "                       3.1636e-01,  4.7320e-02,  8.7320e-02, -3.4560e-02, -2.9647e-02,\n",
       "                      -3.7982e-02,  1.4886e-02, -5.2989e-02,  9.8746e-01, -6.8193e-02,\n",
       "                      -3.2625e-02, -1.5346e-01, -2.7075e-02,  6.2838e-01,  2.8279e-03,\n",
       "                       4.5197e-02,  5.8952e-02, -3.1802e-02,  9.5988e-01, -9.7905e-03,\n",
       "                       7.9155e-03,  2.3047e-02, -7.2088e-02,  1.4285e+00, -1.1744e-01,\n",
       "                       5.9528e+00,  1.0998e-02, -5.2637e-02, -4.6926e-02,  1.2648e-01,\n",
       "                       5.0973e-02, -6.2821e-02,  1.7174e+00, -1.5909e+00, -7.1346e-02,\n",
       "                       1.3065e-02,  1.4208e-03,  1.2072e-02, -5.6179e-02, -8.5790e-01,\n",
       "                       2.4758e-02, -3.7035e-02,  6.5245e-02, -5.7730e-02,  8.8954e-03,\n",
       "                       2.4164e-02,  2.4824e-02, -4.4619e+00, -4.4728e-02,  5.0962e-01,\n",
       "                      -8.7039e-02, -2.5942e-02, -3.4516e-02,  3.4620e-03, -9.6877e-03,\n",
       "                      -2.3957e-02,  7.4723e-01, -8.6680e-02, -8.9123e-03, -9.8669e-03,\n",
       "                       7.7160e-03, -3.8241e-02,  2.4276e-02, -2.7177e-02, -1.4410e-02,\n",
       "                       3.1508e-02, -7.4964e-02, -4.1843e+00, -5.3137e-02,  6.3056e-02,\n",
       "                       1.8977e-01,  1.7206e-02,  5.5730e-02,  9.2577e-02, -5.1854e-02,\n",
       "                      -7.0274e-02,  6.7418e-03,  5.0537e-01, -3.4388e-02, -2.8201e-02,\n",
       "                       1.0878e+00, -4.2922e-02,  1.4395e-02,  9.0368e-02,  1.9523e-02,\n",
       "                      -3.1936e-02,  1.5685e-02, -1.2646e-01,  4.9174e-02,  3.5434e-02,\n",
       "                      -8.2450e-02,  7.0374e-02,  2.0341e+00, -1.2597e-03,  1.7662e-02,\n",
       "                      -2.1654e-02,  1.6980e-02, -2.2264e-02,  1.4201e+00,  3.7995e-02,\n",
       "                      -7.5068e-01, -3.3118e-02, -4.4498e-02, -1.2849e-02,  1.6066e+00,\n",
       "                       7.4442e-03, -2.8391e-02, -3.0426e-02, -6.6916e-02,  3.6943e-02,\n",
       "                       2.4142e+00,  2.6795e-02, -3.0522e-02,  2.2860e-02, -1.2427e+00,\n",
       "                      -5.8671e-03, -3.1937e-02,  6.6950e-02,  1.8334e+00,  8.4234e-01,\n",
       "                      -2.6185e+00,  4.8812e-02,  1.4860e-02,  8.1447e-02,  6.3701e-02,\n",
       "                       6.5082e-01, -2.9362e-02, -5.8465e-03,  1.1432e-02,  9.4156e-02,\n",
       "                      -3.4435e-03, -3.1265e-03,  3.6008e-02, -4.7079e-02,  1.2924e+00,\n",
       "                      -6.3901e-01, -1.1540e-01, -6.8478e-02,  4.0475e-02,  8.4606e-04,\n",
       "                      -5.3172e-02, -3.2074e-02, -5.3179e-01, -7.7267e-02, -9.3067e-01,\n",
       "                       1.0465e-02,  2.9879e-02,  9.6295e-02, -8.4492e-01,  9.2283e-03,\n",
       "                       5.6964e-03,  3.3164e-02, -6.6574e-02, -1.3065e+00,  2.8658e+00,\n",
       "                      -2.6081e-02,  1.8709e-02, -1.5334e-01, -6.5637e-02,  5.4858e-02,\n",
       "                       3.6138e-02,  1.0200e-01,  3.1254e-02,  4.9085e-01,  1.9539e+00,\n",
       "                       6.2651e-02, -9.2777e-03,  3.0763e-02, -2.5738e-02,  4.1722e-03,\n",
       "                       8.7366e-02,  2.2238e+00,  2.1134e-02, -5.8986e-01, -3.3314e-02,\n",
       "                      -2.8740e-01, -2.9460e-02, -6.1012e-02, -8.5327e-02, -1.9449e-02,\n",
       "                      -9.6893e-03, -1.3676e-02,  7.1937e-02, -2.2091e-02,  1.4230e-01,\n",
       "                      -2.9247e-03,  2.0170e-02, -2.1647e-03,  3.7036e-02,  4.8527e-02,\n",
       "                       4.9195e-02,  8.4472e-02,  2.2416e-02, -1.4852e+00, -1.4807e-02,\n",
       "                      -3.8031e-02,  2.1973e-02, -7.2500e-02, -3.7333e+00,  4.4737e-02,\n",
       "                      -2.1547e-02,  1.3280e-01, -1.5869e-02, -7.6116e-02,  5.6696e-02,\n",
       "                      -4.5799e-02,  3.0457e-02, -6.7608e-02, -8.7285e-04,  2.5924e-02,\n",
       "                      -2.4504e-02, -1.2645e-02,  1.2482e-03, -6.6113e-02, -9.2135e-02,\n",
       "                       2.9177e-02,  3.6201e-02, -2.3847e-02, -2.9362e-02,  8.6286e-03,\n",
       "                       2.3079e-01,  8.6678e-02, -2.5348e-02, -6.8976e-01, -9.3424e-03,\n",
       "                      -1.8948e-03, -4.7562e-02,  5.5416e-02, -1.7045e+00, -6.5508e+00,\n",
       "                       8.3486e-02, -1.9009e-02,  9.0974e-02,  7.8328e-04,  1.4130e+00,\n",
       "                       1.6036e-02,  4.6191e-01,  3.8038e-02, -1.4660e-02, -4.3329e-02,\n",
       "                       3.3031e-02, -2.4600e-02,  2.7223e-02, -1.1719e-02,  4.5864e+00,\n",
       "                       2.3815e-02,  5.6883e-02,  1.3673e-02,  3.6454e+00, -1.9934e-02,\n",
       "                      -5.8717e-02,  1.1773e-01, -9.9560e-02, -2.5124e-02,  2.3740e-02,\n",
       "                      -3.0985e+00, -3.1478e-02, -7.8316e-02, -3.5146e-02,  9.9040e-03,\n",
       "                       1.4021e+00,  6.6563e-02, -5.4644e-02, -1.2870e-01, -2.5405e+00,\n",
       "                       4.2900e-02,  6.1753e-02,  2.0181e-02, -2.4604e-01,  3.3899e-02,\n",
       "                      -3.3150e-01,  5.8135e-02, -7.7085e-02, -1.1381e-02, -1.1979e-01,\n",
       "                      -6.9117e-02, -2.9411e+00,  2.5221e-02, -4.9489e-02, -3.1491e-02,\n",
       "                       2.7990e-02, -5.0058e-02, -4.4081e-03, -1.5177e+00, -8.5405e-02,\n",
       "                       1.2394e-03,  8.6393e-02, -1.1114e+00, -5.0037e-02,  1.7472e-02,\n",
       "                      -1.3630e+00, -4.5980e-02, -2.2950e-02,  8.4829e-02,  1.1980e-01,\n",
       "                       3.7789e-01,  1.4256e-02, -1.5798e-02, -7.9670e-02,  1.3425e-02,\n",
       "                       5.3776e-02, -4.1756e-04, -3.2962e-03,  7.0520e-03, -9.7155e+00,\n",
       "                      -4.5005e-01,  2.4250e-02,  4.0714e-02, -3.1054e-02, -7.1486e-02,\n",
       "                       4.2203e-02, -5.1906e-02,  7.7021e-03,  1.4792e+00,  3.7381e-02,\n",
       "                       5.1217e-02, -4.6437e-02,  4.3894e-02, -3.3296e-02,  8.0093e-01,\n",
       "                       5.3487e-02,  1.6498e-02, -7.0296e-02,  2.2401e-02,  1.6126e-03,\n",
       "                       7.3543e-02, -1.0700e-01, -1.6743e-02,  5.2986e-02,  6.5577e-02,\n",
       "                       8.4945e-03, -1.2615e-01, -5.2055e-03,  3.0202e-02,  5.0526e-02,\n",
       "                      -5.3118e-02,  7.8311e-02,  2.8780e-03,  4.4052e-02, -8.2598e-02,\n",
       "                      -6.6497e-02,  4.7504e-02, -7.4999e-02,  7.1661e-02, -2.5020e-02,\n",
       "                      -2.5952e-03,  1.9973e-02, -1.3543e-02, -3.4492e-02,  6.1642e-01,\n",
       "                       4.5948e-02,  7.6479e-02,  4.3117e-02, -4.8325e-03, -7.1525e-03,\n",
       "                      -5.3119e-02,  3.0351e-02, -3.4430e-02, -2.8142e-02,  4.2122e+00,\n",
       "                      -5.2939e-02, -6.7744e-03, -1.6964e-02, -3.0998e-02,  1.3836e-02,\n",
       "                      -3.0749e-02,  9.3860e-01, -3.8323e-02, -4.3151e-02,  3.9946e-02,\n",
       "                       6.5994e-01,  5.8935e-02, -1.0172e-01, -1.8503e-02, -2.2569e-02,\n",
       "                      -4.3130e-02,  3.2620e-02, -3.6883e-02, -3.1892e-02, -6.7825e-02,\n",
       "                      -2.5377e-02,  2.7011e-02, -7.6827e-02,  2.0895e-02,  1.4433e-02,\n",
       "                       5.2398e-02, -6.0426e-02,  4.3787e-02, -6.5104e-02,  4.0303e-02,\n",
       "                       3.5507e-02,  9.1165e-03, -6.9026e-02, -3.1074e-01,  2.7664e-02,\n",
       "                       9.0958e-02,  4.4353e+00,  1.8092e-02,  5.2506e-02, -2.9885e-03,\n",
       "                      -1.4655e-02,  6.9322e-02, -1.0124e-01,  6.3368e-03, -1.0254e-01,\n",
       "                      -2.4014e-02,  3.8090e-01, -3.1257e-02, -5.0670e-04,  3.6725e-02,\n",
       "                       1.6410e+00,  3.3871e-02, -2.8793e-02, -2.4106e-03,  8.6484e-02,\n",
       "                       6.4769e-03, -1.1609e-02, -2.8992e-02, -1.3224e-01,  2.2729e-02,\n",
       "                       9.5682e-02,  8.9547e-02,  4.8403e-02,  1.0771e-03, -2.1712e-01,\n",
       "                       1.6744e-01, -1.6263e-02,  3.2951e-02, -5.8189e-03,  4.4479e-02,\n",
       "                       2.9816e-02, -3.9856e+00], device='cuda:1')),\n",
       "             ('running_std',\n",
       "              tensor([0.0713, 0.9856, 0.0814, 0.0876, 0.0938, 0.0707, 0.0784, 0.0788, 0.0814,\n",
       "                      1.7877, 1.8982, 1.7357, 0.0803, 0.0792, 0.0753, 1.9767, 0.0888, 1.5646,\n",
       "                      0.0740, 1.4050, 0.0804, 0.0749, 0.0864, 0.0775, 0.0709, 0.0751, 2.1636,\n",
       "                      0.0823, 1.6407, 0.0776, 0.0832, 0.0856, 0.0780, 0.0723, 0.0824, 0.0801,\n",
       "                      0.0782, 0.0773, 0.0656, 0.0786, 1.6301, 0.0777, 0.0810, 1.2196, 1.2592,\n",
       "                      1.5716, 1.9821, 0.0711, 0.3331, 0.0718, 1.4151, 0.0769, 0.0690, 0.0742,\n",
       "                      0.0763, 0.0819, 0.0833, 1.5026, 0.0716, 1.3235, 0.0786, 0.0864, 0.0740,\n",
       "                      0.0836, 0.0781, 0.0780, 0.0790, 0.0819, 1.8712, 0.0756, 0.0695, 0.0783,\n",
       "                      0.0760, 0.0727, 0.0751, 0.0741, 0.0920, 0.0662, 0.0789, 0.0806, 0.3130,\n",
       "                      0.0803, 0.0747, 0.0708, 0.0781, 0.0709, 0.0739, 0.0735, 1.6192, 0.0811,\n",
       "                      0.0826, 1.5632, 0.0734, 1.9398, 0.0767, 0.1626, 0.0866, 0.0720, 1.9325,\n",
       "                      0.0701, 0.0773, 0.0743, 0.0806, 1.7656, 0.0872, 2.0071, 0.0809, 0.0794,\n",
       "                      0.0818, 0.0837, 0.0837, 0.0770, 1.2910, 1.8916, 0.0733, 0.0765, 0.0815,\n",
       "                      0.4675, 0.0726, 0.7954, 0.0711, 0.0813, 0.0881, 0.0727, 0.0769, 0.0779,\n",
       "                      0.0845, 1.7690, 0.0701, 1.4668, 0.0790, 0.0751, 0.0834, 0.0749, 0.0839,\n",
       "                      0.0741, 1.4997, 0.0861, 0.0717, 0.0672, 0.0798, 0.0772, 0.0841, 0.0811,\n",
       "                      0.0799, 0.0816, 0.0796, 1.8406, 0.0763, 0.0907, 0.9247, 0.0846, 0.0821,\n",
       "                      0.0707, 0.0718, 0.0838, 0.0734, 1.2932, 0.0777, 0.0740, 1.4837, 0.0790,\n",
       "                      0.0746, 0.0698, 0.0741, 0.0782, 0.0778, 0.0695, 0.0779, 0.0833, 0.0861,\n",
       "                      0.0712, 1.7202, 0.0816, 0.0759, 0.0798, 0.0786, 0.0812, 1.3958, 0.0804,\n",
       "                      1.5538, 0.0818, 0.0715, 0.0827, 1.5154, 0.0778, 0.0897, 0.0768, 0.0830,\n",
       "                      0.0762, 1.9547, 0.0813, 0.0717, 0.0758, 1.0119, 0.0786, 0.0791, 0.0894,\n",
       "                      1.8517, 1.2337, 1.9869, 0.0816, 0.0761, 0.0829, 0.0791, 1.2017, 0.0834,\n",
       "                      0.0748, 0.0742, 0.0825, 0.0881, 0.0806, 0.0831, 0.0799, 1.6990, 1.8077,\n",
       "                      0.0805, 0.0713, 0.0807, 0.0765, 0.0793, 0.0750, 1.8168, 0.0805, 1.8600,\n",
       "                      0.0789, 0.0689, 0.0783, 1.7274, 0.0886, 0.0774, 0.1221, 0.0847, 1.5737,\n",
       "                      1.8829, 0.0735, 0.0849, 0.0783, 0.0771, 1.0352, 0.0752, 0.0830, 0.0788,\n",
       "                      1.2741, 1.5166, 0.0849, 0.0730, 0.0792, 0.0821, 0.0782, 0.8369, 1.6514,\n",
       "                      0.0795, 1.2311, 0.0759, 1.4725, 0.0703, 0.0772, 0.0845, 0.0695, 0.0759,\n",
       "                      0.0794, 0.0805, 0.0722, 0.0801, 0.0783, 0.0833, 0.0791, 0.0787, 0.0803,\n",
       "                      0.0845, 0.0831, 0.0741, 1.4413, 0.0800, 0.0862, 0.0847, 0.0812, 1.9026,\n",
       "                      0.0814, 0.0794, 0.0828, 0.0724, 0.0714, 0.0822, 0.0801, 0.0798, 0.0764,\n",
       "                      0.0814, 0.0770, 0.0765, 0.0757, 0.0800, 0.0709, 0.0933, 0.0759, 0.0828,\n",
       "                      0.0892, 1.0760, 0.0822, 1.5809, 0.0762, 0.0841, 0.7103, 0.0807, 0.0739,\n",
       "                      0.0695, 0.0822, 1.7680, 1.9214, 0.0726, 0.0722, 0.0729, 0.0842, 1.8848,\n",
       "                      0.0706, 1.7593, 0.0737, 0.0775, 0.0760, 0.0728, 0.0843, 0.0708, 0.0779,\n",
       "                      1.5225, 0.0750, 0.0761, 0.0761, 1.9656, 0.0736, 0.0817, 0.0726, 1.8249,\n",
       "                      0.0867, 0.0747, 1.7652, 0.0815, 0.0780, 1.6181, 0.0718, 1.0085, 0.0858,\n",
       "                      0.0779, 0.0811, 1.7397, 0.0742, 0.0804, 0.0800, 1.2844, 0.0814, 1.6097,\n",
       "                      0.0807, 0.0748, 0.0696, 1.7175, 0.0736, 1.4415, 0.0763, 0.0813, 0.0840,\n",
       "                      0.0794, 0.0829, 0.0715, 1.4326, 0.0757, 0.0729, 0.0904, 0.9690, 0.0763,\n",
       "                      0.0739, 1.8136, 0.0774, 0.0764, 0.0815, 0.0852, 1.9134, 0.0827, 0.0767,\n",
       "                      0.0835, 0.0735, 0.0786, 0.0749, 0.0801, 0.0856, 2.0750, 0.7642, 0.0906,\n",
       "                      0.0887, 0.0764, 0.0819, 0.0841, 0.0787, 0.0804, 1.6138, 0.0806, 0.0796,\n",
       "                      1.0093, 0.0825, 0.0848, 1.5211, 0.0817, 0.0757, 0.0808, 0.0797, 0.0776,\n",
       "                      0.0843, 0.0805, 0.0773, 0.0831, 0.0827, 0.0805, 0.0824, 0.0788, 0.0748,\n",
       "                      0.0812, 0.2421, 0.0737, 0.0787, 0.0784, 0.0769, 0.0829, 0.0802, 0.0748,\n",
       "                      0.0793, 0.0777, 0.0861, 0.0709, 0.0785, 0.0788, 0.7917, 0.0818, 0.0771,\n",
       "                      0.0765, 0.0771, 0.0848, 0.0842, 0.1683, 0.0762, 0.0737, 2.0794, 0.0760,\n",
       "                      0.0842, 0.0838, 0.0787, 0.0790, 0.0817, 1.5469, 0.0762, 0.0783, 0.0755,\n",
       "                      1.2167, 0.0711, 0.0722, 0.0673, 0.0795, 0.0723, 0.0833, 0.0786, 0.0752,\n",
       "                      0.0816, 0.0725, 0.0851, 0.0804, 0.0766, 0.0750, 0.0915, 0.0828, 0.0774,\n",
       "                      0.0873, 0.0858, 0.0837, 0.0829, 0.0683, 1.8104, 0.0753, 0.0740, 2.2579,\n",
       "                      0.3312, 0.0748, 0.0736, 0.0849, 0.0721, 1.2180, 0.0857, 0.0767, 0.0679,\n",
       "                      1.3914, 0.0780, 0.0697, 0.0751, 1.4645, 0.0763, 0.0835, 0.0804, 0.0764,\n",
       "                      0.0766, 0.0806, 0.0757, 0.0811, 0.0874, 0.0825, 0.0792, 0.0824, 0.0824,\n",
       "                      0.5107, 1.0831, 0.0764, 0.0744, 0.0659, 0.0847, 0.0848, 1.3976],\n",
       "                     device='cuda:1')),\n",
       "             ('feature_net.0.weight',\n",
       "              tensor([[-0.0096,  0.0170, -0.0165,  ...,  0.0384, -0.0106, -0.0328],\n",
       "                      [ 0.0259,  0.0253,  0.0235,  ...,  0.0094,  0.0076,  0.0160],\n",
       "                      [-0.0013,  0.0030,  0.0452,  ..., -0.0168,  0.0304, -0.0011],\n",
       "                      ...,\n",
       "                      [-0.0314, -0.0540, -0.0411,  ..., -0.0213,  0.0220,  0.0060],\n",
       "                      [-0.0044,  0.0144,  0.0312,  ...,  0.0159, -0.0172,  0.0022],\n",
       "                      [ 0.0293,  0.0119, -0.0214,  ..., -0.0023, -0.0084, -0.0263]],\n",
       "                     device='cuda:1')),\n",
       "             ('feature_net.0.bias',\n",
       "              tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:1')),\n",
       "             ('feature_net.1.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:1')),\n",
       "             ('feature_net.1.bias',\n",
       "              tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:1')),\n",
       "             ('feature_net.3.weight',\n",
       "              tensor([[-2.0778e-02,  6.8948e-03, -8.9534e-03,  ...,  2.7284e-02,\n",
       "                        1.5855e-02, -1.2107e-02],\n",
       "                      [ 2.3431e-02,  1.8254e-02, -4.2106e-02,  ..., -1.0159e-02,\n",
       "                        2.3733e-03, -4.2183e-03],\n",
       "                      [-9.6661e-04,  8.0077e-04,  2.6676e-02,  ..., -8.5798e-03,\n",
       "                        9.5563e-03,  5.3626e-04],\n",
       "                      ...,\n",
       "                      [-3.6654e-02,  2.6287e-02, -1.3566e-02,  ..., -7.7405e-03,\n",
       "                        1.0392e-03,  2.5920e-02],\n",
       "                      [ 7.4614e-05,  1.9754e-02,  1.0973e-03,  ...,  4.5728e-04,\n",
       "                       -4.8036e-03, -8.7746e-03],\n",
       "                      [-1.7457e-02,  2.0242e-03, -1.2116e-02,  ..., -3.1415e-02,\n",
       "                        3.8354e-02,  1.4960e-02]], device='cuda:1')),\n",
       "             ('feature_net.3.bias',\n",
       "              tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:1')),\n",
       "             ('feature_net.5.weight',\n",
       "              tensor([[-0.0048,  0.0258, -0.0229,  ...,  0.0070, -0.0057,  0.0348],\n",
       "                      [-0.0431,  0.0011, -0.0154,  ...,  0.0117,  0.0159,  0.0031],\n",
       "                      [-0.0015,  0.0096, -0.0292,  ..., -0.0210,  0.0365, -0.0209],\n",
       "                      ...,\n",
       "                      [-0.0365, -0.0067,  0.0088,  ...,  0.0281,  0.0238, -0.0034],\n",
       "                      [-0.0220, -0.0376,  0.0207,  ..., -0.0181,  0.0025, -0.0033],\n",
       "                      [ 0.0278,  0.0001,  0.0379,  ...,  0.0085, -0.0279,  0.0010]],\n",
       "                     device='cuda:1')),\n",
       "             ('feature_net.5.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:1')),\n",
       "             ('phi1.0.weight',\n",
       "              tensor([[ 0.1864, -0.0798, -0.0542,  ..., -0.1661, -0.0577, -0.0374],\n",
       "                      [-0.1557,  0.0760, -0.1183,  ..., -0.2397, -0.1696,  0.2891],\n",
       "                      [ 0.5573,  0.0548,  0.0148,  ..., -0.4030, -0.0201, -0.0037],\n",
       "                      ...,\n",
       "                      [ 0.1355, -0.2986,  0.1626,  ...,  0.1638, -0.1023,  0.3251],\n",
       "                      [ 0.1289,  0.6530, -0.1948,  ...,  0.0051, -0.0024, -0.1442],\n",
       "                      [ 0.2511, -0.1960,  0.2813,  ...,  0.1080,  0.0850, -0.1017]],\n",
       "                     device='cuda:1')),\n",
       "             ('phi1.0.bias',\n",
       "              tensor([-0.2877,  0.1714,  0.4462,  ..., -0.1567, -0.3630,  0.0006],\n",
       "                     device='cuda:1')),\n",
       "             ('phi1.1.weight',\n",
       "              tensor([1.6774, 0.4265, 1.6055,  ..., 1.6848, 1.3248, 0.0633], device='cuda:1')),\n",
       "             ('phi1.1.bias',\n",
       "              tensor([-0.1123, -0.0617,  0.3007,  ..., -0.0949,  0.0379,  0.0024],\n",
       "                     device='cuda:1')),\n",
       "             ('phi1.3.weight',\n",
       "              tensor([[ 0.0011,  0.2238,  0.3903,  ..., -0.2588,  0.3786, -0.0462],\n",
       "                      [ 0.1646,  0.6690, -0.5442,  ..., -0.4135, -0.1358,  0.3126],\n",
       "                      [ 0.4135,  0.0535, -0.3990,  ...,  0.7666,  0.1411,  0.0839],\n",
       "                      ...,\n",
       "                      [-0.4012,  0.3923,  0.8249,  ...,  0.2874,  0.7132, -0.4067],\n",
       "                      [ 0.1653,  0.3431,  0.0347,  ...,  0.2325,  0.4617, -0.2514],\n",
       "                      [-0.3097,  0.1582,  0.0399,  ...,  0.2950,  0.2179, -0.1717]],\n",
       "                     device='cuda:1')),\n",
       "             ('phi1.3.bias',\n",
       "              tensor([-0.0157, -0.0949,  0.0985,  ..., -0.2603, -0.0406, -0.1546],\n",
       "                     device='cuda:1')),\n",
       "             ('phi1.4.weight',\n",
       "              tensor([-2.6778e-03,  1.1863e+00,  3.8909e-04,  ...,  1.7195e-03,\n",
       "                      -2.7163e-03, -4.6343e-04], device='cuda:1')),\n",
       "             ('phi1.4.bias',\n",
       "              tensor([ 1.7691e-04, -3.4428e+00,  1.5645e-03,  ...,  1.1583e-03,\n",
       "                       7.7598e-04, -1.0209e-04], device='cuda:1')),\n",
       "             ('phi1.6.weight',\n",
       "              tensor([[-7.7739e-02,  3.5903e-02, -1.0794e-02,  ..., -1.6492e-03,\n",
       "                        3.1837e-03, -1.6868e-02],\n",
       "                      [ 3.1250e-02, -4.4584e-04, -1.3101e-02,  ...,  1.1223e-04,\n",
       "                       -3.9087e-02, -5.1633e-03],\n",
       "                      [-6.6942e-03,  5.7592e-02,  1.1496e-02,  ...,  1.4302e-02,\n",
       "                       -4.5073e-02,  4.2818e-02],\n",
       "                      ...,\n",
       "                      [-9.2492e-02,  1.4803e-01, -6.2282e-02,  ...,  4.1310e-02,\n",
       "                        4.2733e-02,  2.9265e-02],\n",
       "                      [ 4.8013e-03,  6.0960e-02,  2.6410e-02,  ..., -3.0447e-02,\n",
       "                        1.4398e-03,  3.5072e-02],\n",
       "                      [-8.0997e-03,  8.1603e-02,  1.0724e-02,  ..., -3.0678e-02,\n",
       "                        3.6505e-03,  4.6055e-04]], device='cuda:1')),\n",
       "             ('phi1.6.bias',\n",
       "              tensor([-0.0373, -0.0250, -0.0468,  ..., -0.1049, -0.0333, -0.0849],\n",
       "                     device='cuda:1')),\n",
       "             ('phi1.8.weight',\n",
       "              tensor([[ 0.0102,  0.0037,  0.0098,  ...,  0.0142,  0.0072, -0.0011],\n",
       "                      [ 0.0462,  0.0161, -0.0278,  ..., -0.0386, -0.0034,  0.0089],\n",
       "                      [-0.0172, -0.0131,  0.0198,  ...,  0.0042, -0.0211, -0.0082],\n",
       "                      ...,\n",
       "                      [ 0.0042,  0.0286, -0.0036,  ...,  0.0362, -0.0313,  0.0056],\n",
       "                      [ 0.0227,  0.0005,  0.0077,  ..., -0.0233,  0.0032,  0.0025],\n",
       "                      [ 0.0344, -0.0171, -0.0057,  ...,  0.0757,  0.0135,  0.0251]],\n",
       "                     device='cuda:1')),\n",
       "             ('phi1.8.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:1')),\n",
       "             ('phi2.0.weight',\n",
       "              tensor([[ 1.2033e-01,  1.1786e-01, -1.5094e-01,  ..., -2.3754e-01,\n",
       "                        9.0612e-02,  7.1480e-02],\n",
       "                      [-2.0475e-01, -6.8329e-01,  3.9421e-02,  ...,  1.3649e-02,\n",
       "                       -6.8393e-02,  1.1176e-01],\n",
       "                      [ 6.1708e-01,  1.1382e-01, -5.2679e-04,  ...,  2.9555e-02,\n",
       "                       -1.0706e-01,  1.4387e-01],\n",
       "                      ...,\n",
       "                      [ 1.1199e-01,  1.9343e-02,  1.1314e-01,  ..., -8.7631e-02,\n",
       "                       -9.6817e-03,  3.8193e-02],\n",
       "                      [-5.2924e-01, -5.4272e-01, -2.7189e-01,  ...,  1.5093e-01,\n",
       "                       -1.0077e-02,  1.7324e-01],\n",
       "                      [ 1.6762e-01, -2.5460e-01,  2.9131e-01,  ..., -3.5504e-01,\n",
       "                        8.2476e-02,  1.6148e-01]], device='cuda:1')),\n",
       "             ('phi2.0.bias',\n",
       "              tensor([ 0.0405, -0.4527, -0.1698,  ..., -0.1848,  0.0629, -0.0007],\n",
       "                     device='cuda:1')),\n",
       "             ('phi2.1.weight',\n",
       "              tensor([0.0818, 1.8256, 0.0401,  ..., 1.2579, 1.9335, 0.0759], device='cuda:1')),\n",
       "             ('phi2.1.bias',\n",
       "              tensor([-0.0081,  0.0670,  0.0028,  ..., -0.0028, -0.3201, -0.0008],\n",
       "                     device='cuda:1')),\n",
       "             ('phi2.3.weight',\n",
       "              tensor([[ 0.1344, -0.1566,  0.1555,  ..., -0.0967, -0.2040,  0.3387],\n",
       "                      [ 0.3805, -0.3753, -0.0370,  ..., -0.0993, -0.0388,  0.4497],\n",
       "                      [-0.0461, -0.3646, -0.0133,  ..., -0.2270,  0.3710, -0.2653],\n",
       "                      ...,\n",
       "                      [ 0.6388, -0.1789, -0.2634,  ...,  0.0445,  0.0995,  0.5336],\n",
       "                      [-0.0016,  0.2669,  0.0658,  ..., -0.5147,  0.3312,  0.4671],\n",
       "                      [ 0.1112,  0.4123,  0.0080,  ..., -0.1293,  0.0545,  0.2924]],\n",
       "                     device='cuda:1')),\n",
       "             ('phi2.3.bias',\n",
       "              tensor([ 0.1099,  0.0521, -0.1765,  ...,  0.1593, -0.1302,  0.2297],\n",
       "                     device='cuda:1')),\n",
       "             ('phi2.4.weight',\n",
       "              tensor([2.1356e-03, 1.2098e+00, 1.0887e+00,  ..., 3.5117e-03, 4.2836e-03,\n",
       "                      2.4721e+00], device='cuda:1')),\n",
       "             ('phi2.4.bias',\n",
       "              tensor([-0.0013,  0.4226,  0.2873,  ...,  0.0010,  0.0005, -0.3695],\n",
       "                     device='cuda:1')),\n",
       "             ('phi2.6.weight',\n",
       "              tensor([[-0.0225,  0.0134, -0.0241,  ..., -0.0337, -0.0223,  0.1344],\n",
       "                      [-0.0098, -0.0141,  0.0718,  ...,  0.0202,  0.0012,  0.0434],\n",
       "                      [-0.0039,  0.0070, -0.0316,  ...,  0.0042, -0.0226,  0.0244],\n",
       "                      ...,\n",
       "                      [-0.0517, -0.0342,  0.0200,  ..., -0.0016, -0.0072,  0.0165],\n",
       "                      [ 0.0288,  0.0353,  0.0267,  ..., -0.0247,  0.0242,  0.0199],\n",
       "                      [-0.0099, -0.0067, -0.0142,  ..., -0.0171,  0.0261,  0.0269]],\n",
       "                     device='cuda:1')),\n",
       "             ('phi2.6.bias',\n",
       "              tensor([-0.1013, -0.0259, -0.0270,  ..., -0.0095, -0.0237, -0.0139],\n",
       "                     device='cuda:1')),\n",
       "             ('phi2.8.weight',\n",
       "              tensor([[-0.0560,  0.0482,  0.0154,  ...,  0.0120,  0.0104, -0.0294],\n",
       "                      [-0.0481, -0.0141, -0.0057,  ..., -0.0126,  0.0013,  0.0274],\n",
       "                      [ 0.0053, -0.0189,  0.0048,  ...,  0.0298,  0.0164, -0.0034],\n",
       "                      ...,\n",
       "                      [ 0.0008,  0.0398,  0.0058,  ...,  0.0108, -0.0523, -0.0273],\n",
       "                      [ 0.0093,  0.0075,  0.0185,  ...,  0.0198,  0.0427,  0.0093],\n",
       "                      [-0.0197,  0.0173, -0.0121,  ...,  0.0257, -0.0151, -0.0108]],\n",
       "                     device='cuda:1')),\n",
       "             ('phi2.8.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:1')),\n",
       "             ('target_phi1.0.weight',\n",
       "              tensor([[ 0.1849, -0.0780, -0.0510,  ..., -0.1668, -0.0626, -0.0406],\n",
       "                      [-0.1524,  0.0779, -0.1203,  ..., -0.2402, -0.1664,  0.2882],\n",
       "                      [ 0.5591,  0.0588,  0.0138,  ..., -0.4039, -0.0149,  0.0017],\n",
       "                      ...,\n",
       "                      [ 0.1339, -0.2995,  0.1646,  ...,  0.1638, -0.1062,  0.3281],\n",
       "                      [ 0.1300,  0.6571, -0.1926,  ...,  0.0064, -0.0038, -0.1427],\n",
       "                      [ 0.2477, -0.1848,  0.2848,  ...,  0.1039,  0.0872, -0.1012]],\n",
       "                     device='cuda:1')),\n",
       "             ('target_phi1.0.bias',\n",
       "              tensor([-0.2859,  0.1710,  0.4460,  ..., -0.1567, -0.3629,  0.0016],\n",
       "                     device='cuda:1')),\n",
       "             ('target_phi1.1.weight',\n",
       "              tensor([1.6764, 0.4262, 1.6073,  ..., 1.6874, 1.3260, 0.0555], device='cuda:1')),\n",
       "             ('target_phi1.1.bias',\n",
       "              tensor([-0.1109, -0.0619,  0.3000,  ..., -0.0954,  0.0378,  0.0020],\n",
       "                     device='cuda:1')),\n",
       "             ('target_phi1.3.weight',\n",
       "              tensor([[ 0.0043,  0.2251,  0.3921,  ..., -0.2608,  0.3789, -0.0531],\n",
       "                      [ 0.1639,  0.6728, -0.5535,  ..., -0.4121, -0.1307,  0.3110],\n",
       "                      [ 0.4146,  0.0556, -0.3992,  ...,  0.7668,  0.1439,  0.0718],\n",
       "                      ...,\n",
       "                      [-0.4015,  0.3936,  0.8262,  ...,  0.2872,  0.7093, -0.4070],\n",
       "                      [ 0.1629,  0.3381,  0.0315,  ...,  0.2339,  0.4577, -0.2518],\n",
       "                      [-0.3108,  0.1522,  0.0438,  ...,  0.2939,  0.2206, -0.1676]],\n",
       "                     device='cuda:1')),\n",
       "             ('target_phi1.3.bias',\n",
       "              tensor([-0.0138, -0.0963,  0.0987,  ..., -0.2601, -0.0429, -0.1552],\n",
       "                     device='cuda:1')),\n",
       "             ('target_phi1.4.weight',\n",
       "              tensor([-1.5307e-03,  1.1845e+00, -6.7022e-04,  ..., -1.2466e-03,\n",
       "                      -4.2648e-04, -3.5831e-04], device='cuda:1')),\n",
       "             ('target_phi1.4.bias',\n",
       "              tensor([-7.1735e-05, -3.4451e+00,  6.5936e-05,  ...,  1.3709e-04,\n",
       "                      -1.1819e-04,  8.9199e-05], device='cuda:1')),\n",
       "             ('target_phi1.6.weight',\n",
       "              tensor([[-7.7739e-02,  3.5903e-02, -1.0794e-02,  ..., -1.6492e-03,\n",
       "                        3.1838e-03, -1.6868e-02],\n",
       "                      [ 3.1250e-02, -4.4584e-04, -1.3101e-02,  ...,  1.1223e-04,\n",
       "                       -3.9087e-02, -5.1632e-03],\n",
       "                      [-6.6942e-03,  5.7591e-02,  1.1495e-02,  ...,  1.4302e-02,\n",
       "                       -4.5073e-02,  4.2819e-02],\n",
       "                      ...,\n",
       "                      [-9.2492e-02,  1.4803e-01, -6.2282e-02,  ...,  4.1310e-02,\n",
       "                        4.2733e-02,  2.9265e-02],\n",
       "                      [ 4.8014e-03,  6.0960e-02,  2.6410e-02,  ..., -3.0447e-02,\n",
       "                        1.4398e-03,  3.5072e-02],\n",
       "                      [-1.3456e-02,  8.1182e-02,  9.5656e-03,  ..., -2.9109e-02,\n",
       "                        4.2517e-03,  1.4314e-03]], device='cuda:1')),\n",
       "             ('target_phi1.6.bias',\n",
       "              tensor([-0.0373, -0.0250, -0.0468,  ..., -0.1049, -0.0333, -0.0846],\n",
       "                     device='cuda:1')),\n",
       "             ('target_phi1.8.weight',\n",
       "              tensor([[ 0.0102,  0.0037,  0.0098,  ...,  0.0142,  0.0072,  0.0007],\n",
       "                      [ 0.0462,  0.0161, -0.0278,  ..., -0.0386, -0.0034,  0.0079],\n",
       "                      [-0.0172, -0.0131,  0.0198,  ...,  0.0042, -0.0211, -0.0041],\n",
       "                      ...,\n",
       "                      [ 0.0042,  0.0286, -0.0036,  ...,  0.0362, -0.0313,  0.0018],\n",
       "                      [ 0.0227,  0.0005,  0.0077,  ..., -0.0233,  0.0032,  0.0035],\n",
       "                      [ 0.0344, -0.0171, -0.0057,  ...,  0.0757,  0.0135,  0.0245]],\n",
       "                     device='cuda:1')),\n",
       "             ('target_phi1.8.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:1')),\n",
       "             ('target_phi2.0.weight',\n",
       "              tensor([[ 0.1166,  0.1190, -0.1509,  ..., -0.2404,  0.0872,  0.0673],\n",
       "                      [-0.2038, -0.6880,  0.0376,  ...,  0.0122, -0.0687,  0.1228],\n",
       "                      [ 0.6207,  0.1104,  0.0059,  ...,  0.0306, -0.1071,  0.1407],\n",
       "                      ...,\n",
       "                      [ 0.1138,  0.0175,  0.1165,  ..., -0.0819, -0.0108,  0.0368],\n",
       "                      [-0.5289, -0.5362, -0.2733,  ...,  0.1539, -0.0129,  0.1692],\n",
       "                      [ 0.1678, -0.2611,  0.2872,  ..., -0.3545,  0.0757,  0.1526]],\n",
       "                     device='cuda:1')),\n",
       "             ('target_phi2.0.bias',\n",
       "              tensor([ 0.0398, -0.4559, -0.1708,  ..., -0.1848,  0.0642, -0.0023],\n",
       "                     device='cuda:1')),\n",
       "             ('target_phi2.1.weight',\n",
       "              tensor([0.0812, 1.8277, 0.0376,  ..., 1.2616, 1.9335, 0.0685], device='cuda:1')),\n",
       "             ('target_phi2.1.bias',\n",
       "              tensor([-0.0078,  0.0640,  0.0023,  ..., -0.0026, -0.3182, -0.0005],\n",
       "                     device='cuda:1')),\n",
       "             ('target_phi2.3.weight',\n",
       "              tensor([[ 0.1308, -0.1560,  0.1612,  ..., -0.0945, -0.2036,  0.3327],\n",
       "                      [ 0.3767, -0.3737, -0.0406,  ..., -0.0949, -0.0378,  0.4540],\n",
       "                      [-0.0449, -0.3632, -0.0199,  ..., -0.2275,  0.3697, -0.2714],\n",
       "                      ...,\n",
       "                      [ 0.6369, -0.1778, -0.2654,  ...,  0.0485,  0.0987,  0.5297],\n",
       "                      [-0.0022,  0.2653,  0.0646,  ..., -0.5124,  0.3289,  0.4619],\n",
       "                      [ 0.1137,  0.4125,  0.0046,  ..., -0.1231,  0.0506,  0.2937]],\n",
       "                     device='cuda:1')),\n",
       "             ('target_phi2.3.bias',\n",
       "              tensor([ 0.1099,  0.0512, -0.1766,  ...,  0.1572, -0.1294,  0.2296],\n",
       "                     device='cuda:1')),\n",
       "             ('target_phi2.4.weight',\n",
       "              tensor([5.8362e-04, 1.2140e+00, 1.0925e+00,  ..., 3.0616e-03, 1.7129e-04,\n",
       "                      2.4733e+00], device='cuda:1')),\n",
       "             ('target_phi2.4.bias',\n",
       "              tensor([-1.4719e-04,  4.2100e-01,  2.8723e-01,  ..., -7.5433e-05,\n",
       "                      -3.2203e-05, -3.6977e-01], device='cuda:1')),\n",
       "             ('target_phi2.6.weight',\n",
       "              tensor([[-0.0225,  0.0134, -0.0241,  ..., -0.0337, -0.0223,  0.1344],\n",
       "                      [-0.0098, -0.0141,  0.0718,  ...,  0.0202,  0.0012,  0.0434],\n",
       "                      [-0.0039,  0.0070, -0.0316,  ...,  0.0042, -0.0226,  0.0244],\n",
       "                      ...,\n",
       "                      [-0.0517, -0.0342,  0.0200,  ..., -0.0016, -0.0072,  0.0165],\n",
       "                      [ 0.0288,  0.0353,  0.0267,  ..., -0.0247,  0.0242,  0.0199],\n",
       "                      [-0.0099, -0.0067, -0.0142,  ..., -0.0171,  0.0261,  0.0269]],\n",
       "                     device='cuda:1')),\n",
       "             ('target_phi2.6.bias',\n",
       "              tensor([-0.1013, -0.0259, -0.0270,  ..., -0.0095, -0.0237, -0.0139],\n",
       "                     device='cuda:1')),\n",
       "             ('target_phi2.8.weight',\n",
       "              tensor([[-0.0560,  0.0482,  0.0154,  ...,  0.0120,  0.0104, -0.0294],\n",
       "                      [-0.0481, -0.0141, -0.0057,  ..., -0.0126,  0.0013,  0.0274],\n",
       "                      [ 0.0053, -0.0189,  0.0048,  ...,  0.0298,  0.0164, -0.0034],\n",
       "                      ...,\n",
       "                      [ 0.0008,  0.0398,  0.0058,  ...,  0.0108, -0.0523, -0.0273],\n",
       "                      [ 0.0093,  0.0075,  0.0185,  ...,  0.0198,  0.0427,  0.0093],\n",
       "                      [-0.0197,  0.0173, -0.0121,  ...,  0.0257, -0.0151, -0.0108]],\n",
       "                     device='cuda:1')),\n",
       "             ('target_phi2.8.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:1'))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "payload['agent'].feature_learner.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c81b3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/hilp_zsrl/lib/python3.8/site-packages/glfw/__init__.py:917: GLFWError: (65550) b'X11: The DISPLAY environment variable is missing'\n",
      "  warnings.warn(message, GLFWError)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling method, p_randomgoal: 0.375, future: 0.98, discount: 0.96 horizon: 5 use_history_action: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      " ├── data\n",
      " │   ├── actions (11522042, 19) float32\n",
      " │   ├── clock (11522042, 2) float32\n",
      " │   ├── commands (11522042, 11) float32\n",
      " │   ├── dones (11522042,) bool\n",
      " │   ├── privileged (11522042, 24) float32\n",
      " │   ├── proprio (11522042, 44) float32\n",
      " │   ├── rewards (11522042,) float32\n",
      " │   └── terrain (11522042, 221) float32\n",
      " └── meta\n",
      "     ├── ep_start_obs (200000, 4, 76) float32\n",
      "     ├── episode_command_A (200000, 11) float32\n",
      "     ├── episode_command_B (200000, 11) float32\n",
      "     ├── episode_ends (200000,) int64\n",
      "     ├── episode_reward (200000,) float32\n",
      "     └── episode_step_reward (200000,) float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.04s/it]\n"
     ]
    }
   ],
   "source": [
    "from url_benchmark.dataset_utils.hilbert_dataset import HilbertRepresentationDataset\n",
    "\n",
    "dataset = HilbertRepresentationDataset(data_dir=\"/root/workspace/HugWBC/dataset/Mixture/model_0\",\n",
    "                                       use_history_action=False,\n",
    "                                       discount=0.96,\n",
    "                                       obs_horizon=5,\n",
    "                                       full_loading=False,\n",
    "                                       goal_future=0.98,\n",
    "                                       p_randomgoal=0.375)\n",
    "\n",
    "# print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ad67af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs torch.Size([220])\n",
      "next_obs torch.Size([220])\n",
      "future_obs torch.Size([220])\n",
      "discount torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "for k, v in dataset[0].items():\n",
    "    print(k, v.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hilp_zsrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
